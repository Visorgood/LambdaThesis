\subsection{HDFS [VI]}

The Hadoop Distributed File System (HDFS) \cite{HDFSArchitecture} \cite{HDFSUsersGuide} is a distributed data storage that provides high throughput data access, fault-tolerance, ability to hold huge datasets consisting of large files.
The Apache Software Foundation has developed HDFS originally for its web search engine system - the Apache Nutch.
Today it is a widely-used distributed file system, that is an infrastructure for such distributed computational frameworks as Hadoop, Storm, etc.
HDFS allows to use cheap commodity hardware, because it does not require much computational or storage power for one particular node.
It is written in Java, hence, any platform with JVM \cite{JVM} can run HDFS's software.

\subsubsection{Use cases and requirements}

High throughput

Fault-tolerance

Large data sets

simple

cheap

portable

\subsubsection{General structure}

NameNode

DataNode

Way of access and communication

\subsubsection{Replications}

Description

racks and blocks

\subsubsection{Robustness}

Machine failures

heartbeat signal

Data integrity

Rebalansing

NameNode failures

\subsubsection{Data organisation}

Data blocks

Staging

Data pipelining

File deleting and undeleting

Replica Factor changing