\chapter{Summary [VI]}
\label{chap:summary}

The maintainance and processing of the large amounts of data has become a serious issue in the present time.
We have now the immense volume of data from many different sources.
And we can store it for a very low price.
However, it has brought us to the need to invent new methods and approaches of data storage, manipulation and processing.
We need to store it so, that it is robust and can be efficiently accessed.
We must be able to process it in a linearly scalable way.
As a result, the whole new field of computer science and information technology arised - namely Big Data.

In this thesis we have considered the new generic approach for the big data systems - the Lambda architecture.
We started with the description of the Menthal project, that encountered a problem to store and process large amounts of data.
Then we described the classical approaches to do that.
We showed examples of how Google and Facebook solve several big data issues.
Then we examined why and how those standard methods do not fulfill all the requirements of the generic big data system.
We investigated the Lambda architecture, that combines two approaches of data processing - batch and incremental.
We have designed and developed the Speed layer of the Lambda architecture, that completes the whole system in the Menthal project.
We conducted several experiments to measure and compare efficiency of two data processing frameworks - Spark and Storm.

The result of our work is the system, namely the Speed layer of the Lambda architecture, and also practical measurement of this implementation.
To make this system more robust, efficient and flexible additional investigation is required.
Research on different storage systems must be made.
More different setups of the cluster can be tested to achieve good performance.